{
    "contents" : "# Warning 1: custom the following variables in your defined name. Don't be the same with given to you.\n# 说明:变量替换，改下这几个变量的参数\n# \nyourStuID <- \"104753150678\"\nyourCustomDirName <- \"docsDir\"\noutFiles <- \"txt_jpg_files\"\n\n# remove(list = ls())\n# rm(list = ls())\n\n# Part one: random picks 1000 documents ..            ===\n# load the needed library \"tm\" & \"SnowballC\"\n#--------------------------------------Part one:--------------------------------------\n    # install the needed packages \nif (!installed.packages(\"tm\"))\n    install.packages(\"tm\")\n    \nif (!installed.packages(\"SnowballC\"))   # for stemming \n    install.packages(\"SnowballC\")\n\nif (!installed.packages(\"wordcloud\")) \n    install.packages(\"wordcloud\")\n\nif (!installed.packages(\"RColorBrewer\"))\n    install.packages(\"RColorBrewer\")\n\n#--------------------------------------Part one:--------------------------------------\n  # load the needed package into memory...\n  library(\"tm\")\n  library(\"SnowballC\")\n  \n  library(\"RColorBrewer\")\n  library(\"wordcloud\")\n# create a new directory\n#--------------------------------------Part one:--------------------------------------\nnewADir <- function (dirPath) {\n  if (!dir.exists(dirPath))\n    dir.create(dirPath)\n}\n\n# random picks X = 400,Y = 600,T = \"sci.space\" documents from the 20newsgroup-18828 document\ndocsDir <- paste(getwd(),\"/\",yourCustomDirName,sep = \"\")\n# print(\"docsDir:\")\n# print(docsDir)\n\nnewADir(docsDir)\n\nnewADir(paste(getwd(),\"/\",outFiles,sep = \"\"))\n\nscispacepath <- \"20news-18828/sci.space\"\nsciFiles <- list.files(path = scispacepath)\nsciFileCount <- length(sciFiles)\n\n# produce 400 random numbers from x (1:982)\nrandom400Numbers <- function(x) {\n    len <- length(x)\n    nbsVec <- NULL\n    nbsVec <- sample(seq(1,len,by=1),400,replace = F)\n    return (nbsVec)\n}\n\nrandomPos <- random400Numbers(sciFiles)   # random produce 400 numbers from 1 to the length of files that sci.space contains.\nxFileNames <- NULL                        # the vector used to save the 400 random produced Files names \n\ndir_400 <- paste(yourCustomDirName,\"/400\",sep = \"\")\nif (dir.exists(dir_400))\n  unlink(dir_400,recursive = TRUE)\n\nnewADir(dir_400)\n\ndir_1000 <- paste(yourCustomDirName,\"/1000\",sep = \"\")\nif (dir.exists(dir_1000))\n  unlink(dir_1000,recursive = TRUE)\n\nnewADir(dir_1000)\n\n## randomly picks 400 unique documents that belong to topic \"sci.space\"\n## also means procude 400 random nummbers from 1:982(the length of vector sciFiles)\nfor (i in 1:400) {\n  index <- randomPos[i]\n  xFileName <- sciFiles[index]\n  from <- paste(\"20news-18828/sci.space/\",xFileName,sep = \"\")\n  #to <- paste(\"docsDir/txt\",i,sep = \"\")\n  \n  to <- dir_400\n  to01 <- dir_1000\n  #   print(from)\n  #  print(to)\n  \n  #file.copy(from,to,overwrite = TRUE,copy.mode = TRUE)\n  file.copy(from,to01,overwrite = TRUE,copy.mode = TRUE)  #copy 400 files to the 1000 documents..\n\n  fromIdx <- paste(yourCustomDirName,\"/1000/\",xFileName,sep = \"\")\n  toIdx <- paste(yourCustomDirName,\"/1000/\",subNameFor600Files(from),sep = \"\")\n  \n  file.rename(fromIdx,toIdx)\n\n# print(xFileName)\n# print(paste(\"sci.space/\",xFileName,sep = \"\"))\n  \n  xFileNames <- c(xFileNames,sciFiles[index])\n}\n# 数据集有重合的file，没有copy600个文件。。\nprint(\"400 file copy completed..\")\n\ntraverseOtherDir <- function() {\n  news20Dir <- \"20news-18828\"\n  dirList <- dir(news20Dir)\n  \n  dirList <- dirList[-15]\n  #print(dirList)\n  \n  total_files_len <- 0\n  total_files_name_vector <- NULL\n  \n  for (i in 1:length(dirList)) {\n    oneDir <- dirList[i]\n    \n    path <- paste(\"20news-18828/\",oneDir,sep = \"\")\n    \n    oneDir_fileList <- list.files(path)\n    nameVector <- NULL\n    \n    for (j in 1:length(oneDir_fileList)) {\n      item <- paste(path,\"/\",oneDir_fileList[j],sep = \"\")\n      #print(item)\n      nameVector <- c(nameVector,item)\n    }\n    \n    oneDir_filesCount <- length(oneDir_fileList)\n    total_files_len <- total_files_len + oneDir_filesCount\n    \n    total_files_name_vector <- c(total_files_name_vector,nameVector)\n  }\n  \n  return(total_files_name_vector)\n}\n\ntheOtherFiles <- traverseOtherDir()\ntheOtherLen <- length(theOtherFiles)\n\n\nprint(\"其他目录下的文件名：\")\nprint(theOtherFiles)\n\n# find 600 files in the other file directory and replace the name....\nsubNameFor600Files <- function(x) {\n    charCount <- nchar(\"20news-18828/\")\n    \n    startIdx <- charCount + 1\n    stopIdx <- nchar(x)\n    \n    subString <- substr(x,startIdx,stopIdx)\n    subString <- gsub(pattern = \"/\",replacement = \"_\",subString)\n    return (subString)\n}\n\n# print(paste(\"other topics file count :\",theOtherLen,sep = \"\"))\n\nrandomVector <- NULL\nrandomVector <- sample(seq(1,theOtherLen,by=1),600,replace = FALSE)\n\ndir_600 <- paste(yourCustomDirName,\"/600\",sep = \"\")\n\nif (dir.exists(dir_600))\n  unlink(dir_600,recursive = T)\n\nnewADir(dir_600)\n\nfor (j in 1:600) {\n  index <- randomVector[j]\n  fileName <- theOtherFiles[index]\n  \n  from <- fileName\n  to <- dir_600\n  \n  to01 <- dir_1000\n\n  file.copy(from,to01,overwrite = T,copy.mode = TRUE)   #copy 600 files to the 1000 documents... \n\n  #  file.rename(from = fileName,to = paste(getwd(),yourCustomDirName,\"/1000\")subNameFor600Files(fileName))\n  \n  docID <- strsplit(from,split = \"/\")[[1]][3]\n  fromIdx <- paste(yourCustomDirName,\"/1000/\",docID,sep = \"\")\n  toIdx <- paste(yourCustomDirName,\"/1000/\",subNameFor600Files(fileName),sep = \"\")\n  file.rename(fromIdx,toIdx)\n}\n\n#print(\"600 files copy completed.\")\n#print(\"1000 files copy completed.\")\n# print(paste(\"1000 file length :\",length(list.files(path = \"docsDir/1000\"))))\n\n# picks other 600 files from the remaining directory except the dir:sci.space...\n#--------------------------------------Part one END--------------------------------------\n\n\n# Step Two: create the corpus\n#----------------------------------Part Two:------------------------------------------\ndirPth <- paste(getwd(),paste(\"/\",yourCustomDirName,\"/1000\",sep = \"\"),sep = \"\")\n\n#print(dirPth)\nx <- DirSource(directory = dirPth,encoding = \"UTF-8\")\ncid <- VCorpus(x,readerControl = list(reader = x$DefaultReader,language = \"en\"))\n\n# Step Three: text transformation / preprocessing\n#----------------------------------Part Three:------------------------------------------\nstopwordsList <- c(\"a\",\"about\",\"above\",\"after\",\"again\",\"against\",\"all\",\"am\",\"an\",\"and\",\"any\",\n                   \"are\",\"aren't\",\"as\",\"at\",\"be\",\"because\",\"been\",\"before\",\"being\",\"below\",\"between\",\n                   \"both\",\"but\",\"by\",\"can't\",\"cannot\",\"could\",\"did\",\"didn't\",\"do\",\"does\",\n                   \"doesn't\",\"doing\",\"don't\",\"down\",\"during\",\"each\",\"few\",\"for\",\"from\",\"further\",\"had\",\n                   \"hadn't\",\"has\",\"hasn't\",\"have\",\"haven't\",\"having\",\"he\",\"he'd\",\"he'll\",\"he's\",\"her\",\n                   \"here\",\"here's\",\"hers\",\"herself\",\"him\",\"himself\",\"his\",\"how\",\"how's\",\"i\",\"i'd\",\n                   \"i'll\",\"i'm\",\"i've\",\"if\",\"in\",\"into\",\"is\",\"isn't\",\"it\",\"it's\",\"its\",\n                   \"itself\",\"let's\",\"me\",\"more\",\"most\",\"mustn't\",\"my\",\"myself\",\"no\",\"nor\",\"not\",\n                   \"of\",\"off\",\"on\",\"once\",\"only\",\"or\",\"other\",\"ought\",\"our\",\"ours\",\"ourselves\",\n                   \"out\",\"over\",\"own\",\"same\",\"shan't\",\"she\",\"she'd\",\"she'll\",\"she's\",\"should\",\"shouldn't\",\n                   \"so\",\"some\",\"such\",\"than\",\"that\",\"that's\",\"the\",\"their\",\"theirs\",\"them\",\"themselves\",\n                   \"then\",\"there\",\"there's\",\"these\",\"they\",\"they'd\",\"they'll\",\"they're\",\"they've\",\"this\",\"those\",\n                   \"through\",\"to\",\"too\",\"under\",\"until\",\"up\",\"very\",\"was\",\"wasn't\",\"we\",\"we'd\",\n                   \"we'll\",\"we're\",\"we've\",\"were\",\"weren't\",\"what\",\"what's\",\"when\",\"when's\",\"where\",\"where's\",\n                   \"which\",\"while\",\"who\",\"who's\",\"whom\",\"why\",\"why's\",\"with\",\"won't\",\"would\",\"wouldn't\",\n                   \"you\",\"you'd\",\"you'll\",\"you're\",\"you've\",\"your\",\"yours\",\"yourself\",\"yourselves\")\n\n#-----------------------------------------------------------------------------------------\n#-------------------------------------text transformation---------------------------------\ncid <- tm_map(cid,PlainTextDocument)\ncid <- tm_map(cid,content_transformer(tolower))\ncid <- tm_map(cid,removeWords,stopwordsList)\n\ntoSpace <- content_transformer(function(x, pattern) gsub(pattern, \" \",x))\ncid <- tm_map(cid,toSpace,\"[[:punct:]]\")    # remove the punctuation\ncid <- tm_map(cid,toSpace,\"[[:blank:]]\")    # remove the blank character\ncid <- tm_map(cid,toSpace,\"[[:digit:]]\")    # remove the numbers 0-9\n\ncid <- tm_map(cid,stemDocument)\n\n# The File name format is  < sci.space_60392 >\noneKFilesNames <- list.files(path = paste(getwd(),paste(\"/\",yourCustomDirName,\"/1000\",sep = \"\"),sep = \"\"))\n\n## eliminate in the end <>removed afterwards<>\n##  writeCorpus(cid,path = paste(getwd(),\"/writeCorpus\",sep = \"\"),filenames = files)\n\n#-----------------------------------------------------------------------------------------\n#-------------------------------------create the matrix-----------------------------------\ntdm <- TermDocumentMatrix(cid)\n#as.matrix(tdm)\ntdm <- weightTfIdf(tdm,normalize = FALSE)\n\nmatrixName <- function() {\n      n <- paste(yourStuID,\"_matrix.txt\",sep = \"\")\n      \n  if (yourStuID == \"104753150678\")\n      n <- \"Lu_matrix.txt\"\n    \n    return (n)\n}\n\nfilePath <- paste(getwd(),\"/\",outFiles,\"/\",matrixName(),sep = \"\")\nif(!file.exists(filePath))\n    file.create(filePath)\n\n# files <- list.files(path = paste(getwd(),\"/docsDir/1000\",sep = \"\"))\ncolnames(tdm) <- oneKFilesNames\n\ndata <- as.data.frame(inspect(tdm[,]))\nwrite.table(data,file = filePath)\n#-----------------------------------------------------------------------------------------\n\n\n# Step Four: process the query....\n#-----------------------------------------------------------------------------------------\n\n# first,get the query,and cut it into items....\nqueryVector <- scan(file = paste(getwd(),\"/Query/Query.txt\",sep = \"\"),what = \"\")\n# print(queryVector)\n\n# get the matrix's row names,namely through this,we can get the index terms dictionary.\nindexTermsDict <- rownames(tdm)\n# print(length(indexTermsDict))\n#print(indexTermsDict)\n\n# construct a VectorSouce volatile corpus\n#y <- VectorSource(queryVector)\n#print(queryVector)\n#queryCorpus <- VCorpus(y,readerControl = list(reader = y$DefaultReader,language = \"en\"))\n\n#queryCorpus <- tm_map(queryCorpus,PlainTextDocument)\n#queryCorpus <- tm_map(queryCorpus,removeWords,stopwordsList)\n#queryCorpus <- tm_map(queryCorpus,stemDocument)\n\n#----------------------------------------------------------------------------------------------------------------------------\n# process the query vector...\n# queryCorpusPth <- paste(getwd(),\"/txtFiles\",sep = \"\")\n\nx <- DirSource(directory = paste(getwd(),\"/Query\",sep = \"\"),encoding = \"UTF-8\")\nqCorpus <- VCorpus(x,readerControl = list(reader = x$DefaultReader,language = \"en\"))\n\nqCorpus <- tm_map(qCorpus,PlainTextDocument)\nqCorpus <- tm_map(qCorpus,removeWords,stopwordsList)\nqCorpus <- tm_map(qCorpus,stemDocument)\nqCorpus <- tm_map(qCorpus,stripWhitespace)\n\n# <>remove afterwards<>\n#writeCorpus(qCorpus,path = queryCorpusPth,filenames = NULL)\n\ntdm01 <- TermDocumentMatrix(qCorpus)\n#tdm01 <- weightTfIdf(tdm01,normalize = TRUE)  # this sentense does not have meaning here...\n\ntdm01 <- weightTf(tdm01)\n\ntdmData <- as.data.frame(inspect(tdm01[,]))\nq_matrix_path <- paste(getwd(),\"/query_matrix.txt\",sep = \"\")\nif (!file.exists(q_matrix_path))\n    file.create(q_matrix_path)\n\n# put the query matrix to the local disk file...  two columns Matrix,key names & Tf weights\nwrite.table(tdmData,file = q_matrix_path)\n\n#--------------------------------------------------------------------------------------------------------------------------------\n# verify if the terms dictionary contains all the terms in the q vector\n# the method to judge one vector contains the other vector..    --  Improvement point:  --\n\n# be careful of this method's execution time .For this can be a very large execution time ..... 12.7\njudgeTwoVectors <- function(mainV,subV) {\n    foundElems <- NULL\n    for (i in 1:length(subV)) {\n        subElem <- subV[i]\n        for (j in 1:length(mainV)) {\n            mainElem <- mainV[j]\n            if (mainElem == subElem)\n              foundElems <- c(foundElems,subElem)\n        }\n    }\n    \n    return (foundElems)\n}\n \n# construct the query vector Tf-Idf weight.\nquery_vector_afterProcessing <- rownames(tdm01)\n#foundElems <- judgeTwoVectors(indexTermsDict,query_vector_afterProcessing)\n#print(foundElems)\n\nqueryIDF <- NULL\n# caculate the df(i) in the collections:\n\ntdm02 <- TermDocumentMatrix(cid)\ntdm02 <- weightTfIdf(tdm02)\n\nkeywordMatrix <- as.matrix(weightTfIdf(TermDocumentMatrix(cid,list(dictionary = query_vector_afterProcessing))))\ncolnames(keywordMatrix) <- oneKFilesNames\n  \n# print(\"The keyword matrix is :\")\n# print(keywordMatrix)\n\n#---------------------------------------------------------------------------------------------------------------------------\n# pick one column from the keyword matrix\n\n#------------------------------------------------------------------------------------------------------\n## caculate the similarity between the q vector and the d vector \nq <- c(1,1,1,1,1,1,1,1,1,1)   # fully filled with 1 as default.    improvement aferwards...\n\n# non-relevant document id \nnonRelevantDocs <- NULL\nnonRelevantDocs_numb <- 0\n\ncosineQandD <- function (oneColumn,columnName) {\n  \n  numerator <- NULL\n  denominator <- NULL\n  \n  # the similarity value...\n  sim <- NULL\n  \n  #---------------------------------------------------------------------------------------------------------\n  # judge if all elements in the vector equal to 0\n  allElemsEqual0 <- all(oneColumn == 0)\n  if (allElemsEqual0 == TRUE) {\n    print(columnName)\n    print(\"all 0\")\n    \n    nonRelevantDocs <<- c(nonRelevantDocs,columnName)     # write the global variable. \n    nonRelevantDocs_numb <<- nonRelevantDocs_numb + 1\n    \n    print(\"Non-relevant documents Number:\")\n    print(nonRelevantDocs_numb)\n    sim <- 0\n    return (sim)\n  }\n\n  numerator <- crossprod(x = oneColumn,y = q)  \n  denominator <- sqrt(crossprod(oneColumn,oneColumn)) * sqrt(crossprod(q,q))\n  \n  sim <- round(x = (numerator / denominator),digits = 6)\n  \n  return (sim)\n}\n\n# define a vector to store each documents ranking score....\nscoreVec <- NULL # each element of it is a list that has 2 sub-elements: the score & the document ID\nnamesVec <- NULL     # put the column name as the element's name for storage.\n\nfor (k in 1:length(oneKFilesNames)) {\n    columnName <- oneKFilesNames[k]\n    \n    oneColumn <- keywordMatrix[,columnName]\n    # <---------------------------------------------------> #\n      # use for debugging... \n     # print(paste(\"The \",k,\" column:\"))\n    #  print(oneColumn)\n    # <---------------------------------------------------> #\n     \n    score <- 0\n    score <- cosineQandD(oneColumn,columnName)\n   \n    if (score == 0) \n        next\n    \n    # there exists a issue,that the score/columnName maybe NULL,which will cause an strange issue..\n    #if (!is.null(score) && !is.null(columnName)) {\n    #  scElem <- list(SCORE = score,DOCUMENTID = columnName)\n    #  scoreVec <- c(scoreVec,scElem)\n    #}\n    \n    # assign the columnName(also is the document id) for each element's name of the vector \n    scoreVec <- c(scoreVec,score)\n    \n    namesVec <- c(namesVec,columnName)\n    names(scoreVec) <- namesVec\n    \n}\n\n# <-----------------------------------------------------------------------------------------------> #\n# use for debugging... \n\n#    print(\"score vector: \")\n#    print(scoreVec)\n#    print(\"score vector length:\")\n#    print(length(scoreVec))\n\n#    print(\"non-relevant vector:\")\n#    print(nonRelevantID)\n#    print(\"non-relevant vector length:\")\n#    print(length(nonRelevantID))\n    \n    # Test the structure of the score vector..\n#    scoreVec[1]\n#    scoreVec[2]\n#    scoreVec[3]\n    \n#    length(scoreVec)\n    \n#    print(nonRelevantDocs_numb)\n#    print(nonRelevantDocs)\n# <-----------------------------------------------------------------------------------------------> #\n\n#--------------------------------------------------------------------------------------------------------------------------------------\n# sort the score vector \nscoreVec <<- sort(scoreVec,decreasing = TRUE)\n #print(scoreVec)\n    \n#--------------------------------------------------------------------------------------------------------------------------------------\n# construct the sid_results.txt file\n# issues: 1. row names :character not so good.\n#         2. ranking score .6 precision.\n#         3. process the category component.\n#         optimize the above issues.    \n\n    resultsDF <- NULL\n  #  idComponent <- as.numericnames(scoreVec)\n    # component one:\n \n#---------------------------------------------------------------------------------------------------------------------------------------------------------    \n # write the result.txt file algorithm start..\n  \n    # seprate the file name into 2 different parts:\n    id_vector <- NULL\n    category_vector <- NULL\n    \n    names_vector <- names(scoreVec)\n    for (m in 1:length(names_vector)) {\n        name_forOneElem <- names_vector[m]\n        \n        string_afterSpliting <- strsplit(name_forOneElem,split = \"_\")\n        \n        id_vector <- as.numeric(c(id_vector,string_afterSpliting[[1]][2])) \n        category_vector <- c(category_vector,string_afterSpliting[[1]][1])\n    }\n    \n  #  idComponent <- as.numeric(names(scoreVec))\n  #   print(idComponent)\n    \n    # component two:\n #   categoryComponent <- NULL\n    # component three:\n    rankingScComponent <- scoreVec\n #   print(rankingScComponent)\n    \n    resultsDF <- data.frame(documentID = id_vector,category = category_vector,rankingScore = rankingScComponent,stringsAsFactors = FALSE)\n    \n    # row.names(resultsDF) <- as.nc(1:length(scoreVec))\n    row.names(resultsDF) <- c(1:length(scoreVec))       #as.numeric()\n#    print(resultsDF)\n    \n    \n    dfWriteToPth <- paste(getwd(),\"/\",outFiles,\"/Lu_results.txt\",sep = \"\")\n    if (yourStuID != \"104753150678\")\n        dfWriteToPth <- paste(getwd(),\"/\",outFiles,\"/\",yourStuID,\"_results.txt\",sep = \"\")\n    \n    if (!file.exists(dfWriteToPth))\n          file.create(dfWriteToPth)\n    \n    # write the result file to the local disk...\n    write.table(resultsDF,file = dfWriteToPth,row.names = TRUE)\n    # write the result.txt file algorithm Ended.\n#--------------------------------------------------------------------------------------------------------------------------\n    \n#--------------------------------------------------------------------------------------------------------------------------\n  # produce the wordcloud png \n    x <- DirSource(directory = dirPth,encoding = \"UTF-8\")\n    m_corpus <- VCorpus(x,readerControl = list(reader = x$DefaultReader,language = \"en\"))\n    m_corpus <- tm_map(m_corpus,PlainTextDocument)\n    m_corpus <- tm_map(m_corpus,content_transformer(tolower))\n    m_corpus <- tm_map(m_corpus,removeWords,stopwordsList)\n    \n    toSpace <- content_transformer(function(x, pattern) gsub(pattern, \" \",x))\n    m_corpus <- tm_map(m_corpus,toSpace,\"[[:punct:]]\")    # remove the punctuation\n    m_corpus <- tm_map(m_corpus,toSpace,\"[[:blank:]]\")    # remove the blank character\n    m_corpus <- tm_map(m_corpus,toSpace,\"[[:digit:]]\")    # remove the numbers 0-9\n    \n    m_matrix <- TermDocumentMatrix(m_corpus)\n    m_matrix <- as.matrix(m_matrix)\n    colnames(m_matrix) <- oneKFilesNames\n    \n    m_matrix <- m_matrix[,names(scoreVec)]\n#    m_matrix\n#    jpgFileName <- function(x) {\n#       if (x != \"104753150678\")\n#           return (paste(yourStuID,\"_cloud.png\",sep = \"\"))\n        \n#        return (\"Lu_cloud.png\")\n#   }\n    \n#    jpgFileName(yourStuID)\n    \n    jpgFileName <- paste(outFiles,\"/Lu_cloud.jpg\",sep = \"\")\n    if (yourStuID != \"104753150678\") {\n        jpgFileName <- paste(outFiles,\"/\",yourStuID,\"_cloud.jpg\",sep = \"\")\n    } \n  \n    png(jpgFileName,width = 1000,height = 800)              \n    \n    v <- sort(rowSums(m_matrix),decreasing = TRUE)\n    d <- data.frame(word = names(v),freq = v)\n    pal2 <- brewer.pal(8,\"Dark2\")\n    wordcloud(d$word,d$freq,scale = c(10,1),\n                        max.words = 50,\n                        random.order = FALSE,\n                        random.color = F,\n                        ordered.colors = F,\n                        rot.per = .15,\n                        colors = pal2)\n          dev.off()\n#    colnames(m_matrix) <- NULL\n    \n#    comparison.cloud(m_matrix,\n#                     max.words = 1000,\n#                     scale = c(5,0.5),\n#                     random.order = FALSE,\n                     \n#                     rot.per = 0.1,\n                #     colors = brewer.pal(8,\"Dark2\"),\n#                     random.color = F,\n#                     ordered.colors = F,\n#                     colors = c(\"red\",\"orange\",\"yellow\",\"green\",\"cyan\",\"blue\",\"purple\"),\n#                     title.size = 1.4)\n    \n#    dev.off()\n#--------------------------------------------------------------------------------------------------------------------------\n\n#--------------------------------------------------------------------------------------------------------------------------\n# retrieval evaluation:   \n# procedures:\n          \n#         1. random picks 10 relevant documents from the 400 files random picked from the sci.space fileholder.\n              # (This will be the relevant document. [R] for representation)\n#         2. For the answer document sets.namely the files from the sid_results.txt,compare if there exists 10 files\n            # that appears in the R sets. and caculate the '11 standard recall levels'\n#         3. using the plot function to plot the recall versus precison curve \n#         4. caculate the F1 measure for the 10 percent recall level.   F1 = 2*p*r / (p + r)\n#         5. save the graph file sid_eval.f1.jpg to the disk..\n          \n#--------------------------------------------------------------------------------------------------------------------------\n# 1.define the global variables that maybe used for the forthcoming.\nRDocsID <- NULL\nprint(xFileNames)\nrandom10DocsID <- sample(seq(1,400,by=1),10,replace = FALSE)\n\nfor (ii in 1:10)\n    RDocsID <- c(RDocsID,xFileNames[random10DocsID[ii]])\n\n# print(RCollections)\n\nAnswerSets <- NULL\nAnswerSets <- id_vector    # get the id_vector(docoumentID) component as the answer sets...\n\n# 2.judge how many elems that occurs in the R collection that appears in the answersets.\nfindMatchedElems <- function (R,A) {\n    matchedElemsCount <- 0\n    \n    R_len <- length(R)\n    A_len <- length(A)\n    \n    for (ii in 1:A_len) {\n        elemsInA <- A[ii]\n        \n        for (jj in 1:R_len) {\n            if (R[jj] == elemsInA) \n              matchedElemsCount <- matchedElemsCount + 1\n        }\n    }\n    \n    return (matchedElemsCount)\n}\n\n# counts <- findMatchedElems(c(1,2,3,4,5,6,7,8,9,10),c(2,3,4))    # test the function\n\n# find out how many elements appear in R occurs in A\nmatchedElemsCount <- findMatchedElems(RDocsID,AnswerSets)\ntempVector <- RDocsID    # a temp vector to save the element in R. and when matches a element,remove it,so \n                   # the length of the document reduce 1,and will get a more fast executing speed which will enhance the efficency.\nprint(tempVector)\n\nprecisionVector <- NULL   # a vector to save the precision of 11 standard level values from (0.0 0.1 0.2 .... 1.0)\nrecallCount <- 0  # statistic how many recall level that have returned....\n\nprecision <- NULL\ntheNextLoopIndex <- 1    # store the index while we needn't  to loop for all the elements.\n\n#while (recallCount < matchedElemsCount) {\n   # for (ii in 1:length(id_vector)) {\n  #      aAnswerElem <- id_vector[ii]\n   #     if (any(RDocsID == aAnswerElem)) # find a matched elements. namely recall a relevant-document.\n  #      {\n  #          recallCount <- recallCount + 1\n   #     }  \n  #  }\n  #  recallCount <- recallCount + 1\n#}\n\nfor (ii in 1:length(id_vector)) {\n    aAnswerElem <- id_vector[ii]\n    if (any(RDocsID == aAnswerElem)) {  # find a matched elements. namely recall a relevant-document.\n        recallCount <- recallCount + 1\n        \n        precision <- c(precision, recallCount / ii)\n    }\n    \n    if (recallCount == matchedElemsCount) \n      break\n}\n\np_len <- length(precision)\nprint(\"Precision length:\")\nprint(p_len)\n\nif (p_len < 10) {\n    offNumbs <- 10 - p_len\n    x <- rep(precision[p_len],times = offNumbs)\n    precision <- c(precision[1],precision[1:p_len],x)   # re-construct the precision vector... \n                                                        # that represent the 11 standard recall levels\n}\n\nP <- precision[2]\nR <- 0.1\n\nf1_measure <- 2*P*R/(P+R)     # caculate the F1 measure..\n\nprint(\"Precision:\")\nprint(precision)\n\n#--------------------------------------------------------------------------------------------------------------------------------\n# save the plot to local disk .... \n\nplotFileName <- paste(getwd(),\"/\",outFiles,\"/Lu_eval_\",round(f1_measure,2),\".jpg\",sep = \"\")\nif (yourStuID != \"104753150678\")\n  plotFileName <- paste(getwd(),\"/\",outFiles,\"/\",yourStuID,\"_eval_\",round(f1_measure,2),\".jpg\",sep = \"\")\n\njpeg(filename = plotFileName,width = 800,height = 600,units = \"px\",quality = 75,res = NA)\n# plot the recall versus precision curve graph..\nyValues <- c(precision) * 100\ng_range <- range(0,yValues)\n\nmax_y <- ceiling(max(yValues)) \n\nplot(yValues,type = 'o',col = 'black',ylim = g_range,axes = FALSE,ann = FALSE)\naxis(1,at = 1:11,lab = c(0,10,20,30,40,50,60,70,80,90,100))\naxis(2,las = 1,at = ceiling((max_y / 5))*(0:max_y))     # has issues..\n\nbox()\n\nlines(yValues,type = 'o',pch = 19,lty = 20,col = \"black\")\n\ntitle(main = \"Recall/Precision Curve\",col.main = 'red',font.main = 4)\ntitle(xlab = \"Recall\",col.lab = rgb(1,0,0),font.main = 5)\ntitle(ylab = \"Precision\",col.lab = rgb(1,0,0),font.main = 5)\n\ndev.off()\n#--------------------------------------------------------------------------------------------------------------------------------\n#----------------------------------------------END-------------------------------------------------\n",
    "created" : 1449495013536.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "749016216",
    "id" : "FB563507",
    "lastKnownWriteTime" : 1449848328,
    "path" : "~/textMining/textMining.R",
    "project_path" : "textMining.R",
    "properties" : {
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "type" : "r_source"
}